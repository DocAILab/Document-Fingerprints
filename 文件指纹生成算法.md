# 文件指纹生成算法

---

## 一、代码中需要生成文件指纹的四种数据类型

在文件指纹生成代码种，我们需要对四种类型的数据进行指纹生成

（str、float、set()、dict())

1. `domain_pred_res`: 领域预测结果，str

2. `domain_pred_match_num`: 领域预测结果的置信度，float

3. `words`: 文件名 / 标题关键词提取结果，set 其中不包括跨领域词

4. `file_key_word` 存储schema和对应schema的结果`dict()`为``string:list` list中为提取出的信息

---

## 二、生成指纹的算法


需求：对于相似的文本生成的Hash值也要相似
### **0、hashlib库**
hashlib是Python标准库中的一个模块，提供了多种最基本的哈希算法，包括MD5、SHA-1、SHA-256等。

```python
import hashlib

# algorithm='md5'/'sha1'/'sha256'
hash_object = hashlib.new(algorithm)
hash_object.update(data)
```

### **0、ssdeep库**
ssdeep 是一种用于计算文件和文本之间相似性的工具，基于 Nilsimsa 算法，可以生成文档的哈希值，用于比对文档的相似性。在 Python 中，可以使用 ssdeep 库进行文档指纹的计算和比对

对比两个文件相似度，python 中可通过`difflib.SequenceMatcher/ssdeep/python\_mmdt/tlsh` 实现，在大量需要对比，且文件较大时，需要更高的效率，可以考虑模糊哈希（fuzzy hash）

PS：直接使用pip install XXX指令在本地环境配置有点问题

> 解决下载安装包，直接安装pip install .\ssdeep-windows-32\_64-master.zip
>
> 安装包在官网可以下下载
>
> 参考：Python 利用模糊哈希实现对比文件相似度详解
>
> https://my.oschina.net/u/3905674/blog/8400953>

```
import ssdeep

ssdeep\_hash = ssdeep.hash(file\_content)
```

### **1、Simhash**

#### 原理

**Simhash**是一种用于文本相似性比较的哈希算法， google 用来处理海量文本去重的算法，可以将一个文档转换成一个 64 位的字节（特征字）。Simhash可以基于文本内容的特征向量，对相似的文本生成相似的哈希值（具有较好的局部变化容忍性，对于细微差异的文本可以生成相似的指纹）。

**算法步骤**：

1. **分词**：对文本进行分词，提取n个关键词作为表征该文本的特征。(可选步骤：对特征词根据行业领域进行加权）
1. **哈希**：通过hash算法（普通的随意一个即可）将特征词转换为hash值
1. **加权**：分词权重与分词哈希值相乘（具体而言哈希签名为1的位正乘，0的位负乘）
1. **累加**：将各特征词的特征向量累加形成一个序列串
1. **二值化**：将序列串转化为0-1串（也就是向量指纹）（具体来说每一位若>0，转化为1；<0转化为0）
1. **比较**：（相似度计算-汉明距离）

**算法原理图：**

![TULNEBAAJU](doc picture/指纹1.001.png)

**例子：**

![TULNEBAAZI](doc picture/指纹1.002.jpeg)

**特点：**

* 局部敏感（local sensitive）

  > 有点像词袋模型，SimHash在计算文本的哈希签名时，通常会对文本中的每个特征（例如，单词）分别进行哈希。相似的文本在某个局部特征上的相似性将导致它们在哈希签名中的某些位上相同。
  

**应用场景：**一般是对**文本大于500+**的内容提前指纹做相似度比较，如果文本较短的话，相似度就会有较大的偏差。（原因：由于汉明距离实际是计算的将一个字符串转换为另一个字符串所需的最小替换次数。如果文本短，一个词改变后，由于该词占的词频比例较大，权重大，影响的最终指纹结果程度大，对结果相似度的影响也很大）

**参考教程**：

[海量数据去重之SimHash算法简介和应用 - 墨天轮 (modb.pro)](https://www.modb.pro/db/115729)

[simhash - 大辉_FFf - 博客园 (cnblogs.com)](https://www.cnblogs.com/do-your-best/p/9846174.html)（包含相似度计算）

[simhash - 码农教程 (manongjc.com)](http://www.manongjc.com/detail/22-ogzpqhxcibhxigw.html)

[(107条消息) 文本相似度计算——Simhash算法（python实现）*simhash文本相似度*Trisyp的博客-CSDN博客](https://blog.csdn.net/Trisyp/article/details/113623966?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-1-113623966-blog-104106867.235%5Ev38%5Epc_relevant_anti_t3_base&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-1-113623966-blog-104106867.235%5Ev38%5Epc_relevant_anti_t3_base&utm_relevant_index=2)


---

#### 代码

```python
from simhash import Simhash


def generate_simhash_fingerprint(text):
    simhash = Simhash(text)  # 默认指纹维度64，hash_func默认md5
    # 返回一个十六进制hash指纹
    # return hex(simhash.value)
    # 返回一个Simhash对象（便于之后使用内置函数求语义距离）
    return simhash


def calculate_similarity(simhash1, simhash2):
    distance = simhash1.distance(simhash2)
    similarity = 1 - (distance / 64)  # 假设Simhash的num_perm为64
    return similarity


if __name__ == '__main__':
    str1 = '北京增值税电子普通发票.pdf'
    str2 = '福建增值税电子普通发票.pdf'
    str3 = '福建工程学院计算机学院培养方案.pdf'

    # 生成文件指纹并打印
    fingerprint1 = generate_simhash_fingerprint(str1)
    fingerprint2 = generate_simhash_fingerprint(str2)
    fingerprint3 = generate_simhash_fingerprint(str3)
    print(f"文件指纹1: {bin(fingerprint1.value)}")
    print(f"文件指纹2: {bin(fingerprint2.value)}")
    print(f"文件指纹3: {bin(fingerprint3.value)}")

    # 计算相似度
    similarity_12 = calculate_similarity(fingerprint1, fingerprint2)
    similarity_13 = calculate_similarity(fingerprint1, fingerprint3)
    similarity_23 = calculate_similarity(fingerprint2, fingerprint3)

    print(f"相似度1和2: {similarity_12}")
    print(f"相似度1和3: {similarity_13}")
    print(f"相似度2和3: {similarity_23}")

```

1. **指纹生成**

   使用 `generate_simhash_fingerprint()` 函数生成每个text字符串的 Simhash 指纹

   Simhash算法使用哈希函数将文本的特征转换为一个64位的二进制数，每个位上的值代表了该特征的重要性。该值可通过`.value`得到。同时该类提供了`.distance()`函数方便两个实例计算海明距离，以方便查看和比较。

2. **指纹相似度计算**

   `calculate\_similarity() `函数计算两两之间的相似度

   1. 计算 simhash1 和 simhash2 之间的**汉明距离**，即两个 Simhash 值在二进制形式下不同位的数量。
   2. 将汉明距离除以 Simhash 的长度，假设 Simhash 的长度为 64（num\_perm 的默认值）。
   3. 计算相似度，通过用 1 减去步骤 2 中得到的比值，得到一个相似度值。
   4. 返回相似度值。

   **汉明距离**（Hamming distance）是衡量两个 Simhash 值之间差异程度的度量。在信息论中，两个等长字符串之间的汉明距离是两个字符串对应位置的不同字符的个数。

   > 在这里，相似度是通过汉明距离计算得到的，值越接近 1，表示两个 Simhash 值越相似。因此，返回的相似度值越接近 1，表示两个 Simhash 值越相似。一般情况下，如果相似性大于某个阈值（例如0.8或0.9），我们可以认为两个Simhash值代表的文本或数据在内容上相似，可以视为相同或者具有相似性。
   >
   > 例如下： 10101 和 00110 从第一位开始依次有第一位、第四、第五位不同，则海明距离为 3.
   >
   > 汉明距离是指两个**等长字符串**之间对应位置上不同字符的个数。这种距离计算方法可能并不适用于所有情况，特别是在文本长度差异较大时。可以尝试其他相似度计算方法，例如**余弦相似度**等，看看是否能得到更合理的结果。
   >
   > 谷歌经过工程验证认为当两个64bit的二值化simhash值的汉明距离超过3则认为不相似，所以判重问题就转换为求两个哈希值的汉明距离问题

3. **测试效果：还不错(适合于长文本的str类型数据)**

   ```
   文件指纹1: 0b1010011111110100100000101000010010110101000110100100011010111101
   文件指纹2: 0b1000111111110100100000101000000010110101011110100100011110111110
   文件指纹3: 0x663f036b9eb10ab7
   相似度1和2: 0.875
   相似度1和3: 0.515625
   相似度2和3: 0.484375
   ```



### 2、Minhash

#### 原理

Minhash（最小哈希）是一种用于**集合**相似性比较的哈希算法，可以用于处理文本的相似性。通过对文本内容进行集合表示，然后使用Minhash算法生成指纹。相似的文本内容会生成相似的Minhash指纹。主要用于计算两个集合的Jaccard相似度，其中Jaccard相似度表示两个集合的交集大小与并集大小的比值。

**算法原理图：**

![image-20231214171725760](doc picture\image-20231214171725760.png)

> 实际中我们不必对矩阵的行真的进行排列运算，而是可以采用hash函数来对行号进行变换，不同的hash函数对应不同的行排列，从而构建一组minhash结果，而这就是该集合的minhash签名（指纹）

**算法步骤：**

1. **分词**： 首先对文件进行分词或处理，将文件拆分成一系列元素（如词语、字符等）。
1. **哈希**：对每个元素进行哈希，得到一个哈希值（相当于为每个元素确定一个行号）。
1. **矩阵化**：构建一个signature matrix（签名矩阵），其中每一列代表一个哈希函数对所有元素的哈希值进行映射（每个元素的原始行号-->hash后的行号）。
1. **Minhash**: 对于每个哈希函数（每一列），找到其对应列中的最小哈希值（也就是新排列中行号最小的元素），这些最小值共同构成一个指纹向量。
1. **相似度计算**：使用Jaccard相似度来比较两个文件的指纹相似度。Jaccard相似度是两个集合的交集大小除以并集大小，用来度量两个集合之间的相似性。

**例子：**

`Min-hashing`定义为：特征矩阵按行进行一个随机的排列后，第一个列值为1的行的行号。举例说明如下，假设之前的特征矩阵按行进行的一个随机排列如下：

|**元素**|**S1**|**S2**|**S3**|**S4**|
| :- | :- | :- | :- | :- |
|他|0|0|1|0|
|成功|0|0|1|1|
|我|1|0|0|0|
|减肥|1|0|1|1|
|要|0|1|0|1|
`　　`最小哈希值：h(S1)=3，h(S2)=5，h(S3)=1，h(S4)=2.

**特点：**

* 局部敏感（local sensitive）

  >  对于两个集合S1,S2来说，我们知道在前面的矩阵的所有行中，他们的值同时为1的行有|S1∩S2|个；一个是1一个是0的行有|S1∪S2|−|S1∩S2|个。那么在对行进行随机排列之后，从上往下数同时为1的行比一个为1一个为0的行先出现的概率就是|S1∩S2|/|S1∪S2|。而这恰巧就是两个集合的Jaccard相似度。
  >
  >  也就是说在每一次最小哈希的过程中，两个集合的minhash相等的概率就是两个集合的Jaccard相似度。这就保证了所有minhash组成的签名之间相等的概率也等于对应集合的Jaccard相似度。因此从集合到minhash签名，相似度被保留了下来。

**应用场景：**适用于大规模数据集合的相似性问题，**适合set数据类型**。Minhash算法是一个近似算法，相似性的计算结果并不是完全精确的

**参考教程**：

[文本内容相似度计算方法：minhash – 标点符 (biaodianfu.com)](https://www.biaodianfu.com/minhash.html)

[最小哈希签名（MinHash）简述-腾讯云开发者社区-腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/2162118)

[文本去重之MinHash算法 - pathenon - 博客园 (cnblogs.com)](https://www.cnblogs.com/pathenon/archive/2012/07/17/2595778.html)

[minHash最小哈希原理 - stardsd - 博客园 (cnblogs.com)](https://www.cnblogs.com/sddai/p/6110704.html)


---
#### 代码

```python
from datasketch import MinHash, MinHashLSH


def ngrams(text, n=3):
    """
    生成N-gram序列。
    :param text: 要生成N-gram序列的文本。
    :param n: N-gram的大小。
    :return: N-gram序列。
    """
    ngrams = []
    for i in range(len(text) - n + 1):
        ngrams.append(text[i:i + n])
    return set(ngrams)


# 定义函数，用于生成MinHash
def generate_minhash(data, num_perm):
    minhash = MinHash(num_perm=num_perm)
    for item in data:
        # MinHash类的逻辑是提前确定好128个hash映射关系，每新增一个元素，重新算一遍该元素的128种映射结果，再和之前的128个最小值结果去比较，如果小于，则更新该位置的值，否则不更新
        minhash.update(item.encode('utf8'))
    return minhash


# 定义一个函数，用于计算两个文档指纹的Jaccard相似度
def jaccard_similarity(minhash1, minhash2):
    return minhash1.jaccard(minhash2)


# 直接对两个set类型数据计算Jaccard相似度
def jaccard_similarity2(set1, set2):
    intersection = len(set1.intersection(set2))
    union = len(set1.union(set2))
    return intersection / union


# 一个用于在大规模数据中进行快速相似项查询的方法
def minhashLSH_search(minhash_sets, query_set, threshold=0.5, num_perm=128):
    lsh = MinHashLSH(threshold=threshold, num_perm=num_perm)  # threshhold是判定是否相似的jaccard阈值
    for name, set in minhash_sets.items():
        lsh.insert(name, set)
    return lsh.query(query_set)


if __name__ == '__main__':
    # 定义两个示例的set类型数据
    set1 = {'apple', 'banana', 'orange', 'grape'}
    set2 = {'apple', 'watermelon', 'banana', 'kiwi'}
    str3 = '北京增值税电子普通发票.pdf'
    str4 = '福建增值税电子普通发票.pdf'
    str5 = '福建工程学院计算机学院培养方案.pdf'

    # 使用MinHash生成文件指纹
    num_perm = 128  # MinHash的num_perm参数，影响MinHash的精度
    minhash1 = generate_minhash(set1, num_perm)
    minhash2 = generate_minhash(set2, num_perm)
    minhash3 = generate_minhash(ngrams(str3, 1), num_perm)
    minhash4 = generate_minhash(ngrams(str4, 1), num_perm)
    minhash5 = generate_minhash(ngrams(str5, 1), num_perm)

    # 打印哈希值
    print(f"文件指纹1: {minhash1.digest()}")
    print(f"文件指纹2: {minhash2.digest()}")
    print(f"文件指纹3: {minhash3.digest()}")
    print(f"文件指纹4: {minhash4.digest()}")
    print(f"文件指纹5: {minhash5.digest()}")

    # 使用Jaccard相似度计算相似度
    similarity = jaccard_similarity(minhash1, minhash2)
    print("文档指纹Jaccard相似度：", similarity)
    similarity2 = jaccard_similarity2(set1, set2)
    print("文档集合Jaccard相似度：", similarity2)
    similarity34 = jaccard_similarity(minhash3, minhash4)
    print("3和4两个文本的文档指纹Jaccard相似度：", similarity34)
    similarity35 = jaccard_similarity(minhash3, minhash5)
    print("3和5两个文本的文档指纹Jaccard相似度：", similarity35)
    similarity45 = jaccard_similarity(minhash4, minhash5)
    print("4和5两个文本的文档指纹Jaccard相似度：", similarity45)

    # 使用MinHashLSH查询相似项（这一步可以在大规模数据中进行快速相似项查询）
    sets = {"set1": minhash1, "set2": minhash2, "set3": minhash3, "set5": minhash5}
    result = minhashLSH_search(sets, minhash4)
    print("MinHashLSH查询相似项：", result)
```

1. **指纹生成**

   `generate_minhash()`函数：用于生成MinHash。这个函数接受一个字符串类型的集合data和num\_perm参数，其中num\_perm会影响MinHash的精度，它表示生成MinHash时使用的哈希函数数量，默认为128。

2. **指纹相似度计算**

   `jaccard_similarity()`函数，用于计算Jaccard相似度。Jaccard相似度是两个集合的交集大小除以并集大小的比值，用于衡量两个集合的相似程度。

   **Jaccard相似度**是一种度量集合相似性的指标，它衡量两个集合的交集大小与并集大小的比例。对于使用Minhash生成的两个文件指纹，它们可以看作是两个集合，其中包含了一系列的哈希值。

   Jaccard相似度的计算公式如下：

   $$Jaccard相似度 = (两个集合的交集大小) \div (两个集合的并集大小)$$

   Jaccard相似度的取值范围在0到1之间，值越接近1表示两个文件的内容越相似，值越接近0表示两个文件的内容越不相似。

3. **效果：还不错（适合于set类型数据）**

   ```
   文件指纹1: [ 200169630 1298872416  ...]
   文件指纹2: [1851615388  303413502 ...]
   文档指纹Jaccard相似度： 0.328125
   文档集合Jaccard相似度： 0.3333333333333333
   文档集合Jaccard相似度： 0.3333333333333333
   3和4两个文本的文档指纹Jaccard相似度： 0.8046875
   3和5两个文本的文档指纹Jaccard相似度： 0.1484375
   4和5两个文本的文档指纹Jaccard相似度： 0.203125
   MinHashLSH查询相似项： ['set3']
   ```



### 3、Karp-Rabin卡普-拉宾算法(&#x2716;)

#### 原理

Karp-Rabin是一种字符串匹配算法，用于在一个长文本中高效地查找一个短模式的出现位置。该算法是由Michael O. Rabin和Richard M. Karp于1987年提出的。

Karp-Rabin算法的核心思想是通过哈希函数对模式和文本中的子串进行哈希计算，然后比较哈希值来判断是否匹配。它使用了一种滑动窗口的方法，在文本中滑动一个与模式长度相同的窗口，通过哈希函数计算窗口内子串的哈希值，并将其与模式的哈希值进行比较。

具体步骤如下：

1. 计算模式的哈希值和第一个窗口子串的哈希值。

2. 在文本中滑动窗口，每次滑动一个字符，并通过哈希函数计算新窗口子串的哈希值。

3. 将新窗口子串的哈希值与模式的哈希值进行比较，如果相等，则说明找到了一个匹配。

4. 如果哈希值不相等，继续滑动窗口，重复步骤3。

**特点：**

* 只能比较“硬相似度”，没有集合的思想，如果两个文段的相同内容出现在不同位置，该算法会认为二者是完全不同的，而不能像minhash等算法提取出相似性

**应用场景：**主要用于字符串匹配，因此适合处理字符串类型的数据，比如str

**参考教程：**[Rabin–Karp 算法 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/563551141?utm_id=0)

[Rabin-Karp算法 - 简书 (jianshu.com)](https://www.jianshu.com/p/e20994e5e33c)

[Rabin-Karp算法概述 - ChristianL - 博客园 (cnblogs.com)](https://www.cnblogs.com/christianl/p/13747580.html)

---
#### 代码

```python
import hashlib


def generate_karprabin_fingerprint(text, window_size=5, base=256, prime=101):
    """
    使用Karp-Rabin算法生成文本的指纹（哈希值）。
    :param text: 要生成指纹的文本。
    :param window_size: 滑动窗口的大小。
    :param base: 基数，用于计算哈希值。
    :param prime: 大素数，用于计算哈希值。
    :return: 文本的指纹（哈希值）。
    """
    # 初始化哈希值
    hash_value = 0
    # 存储所有窗口的哈希值
    window_hashes = []

    # 计算窗口内的初始哈希值
    for i in range(window_size):
        hash_value = (hash_value * base + ord(text[i])) % prime
    window_hashes.append(hash_value)

    # 滑动窗口生成哈希值
    for i in range(1, len(text) - window_size + 1):
        # 移除滑动窗口前一个字符的贡献
        hash_value = (hash_value - ord(text[i - 1]) * pow(base, window_size - 1, prime)) % prime
        # 添加滑动窗口后一个字符的贡献
        hash_value = (hash_value * base + ord(text[i + window_size - 1])) % prime
        # 存储当前窗口的哈希值
        window_hashes.append(hash_value)

    # 将所有窗口的哈希值连接起来，作为整个字符串的指纹
    fingerprint = ''.join(str(h) for h in window_hashes)

    return fingerprint


def hamming_distance(hash1, hash2):
    """
    计算两个字符串之间的汉明距离。
    :param hash1: 第一个字符串的哈希值。
    :param hash2: 第二个字符串的哈希值。
    :return: 汉明距离。
    """
    distance = sum(bit1 != bit2 for bit1, bit2 in zip(hash1, hash2))
    return distance


def calculate_similarity(hash1, hash2):
    """
    计算两个字符串之间的相似度。
    :param hash1: 第一个字符串的哈希值。
    :param hash2: 第二个字符串的哈希值。
    :return: 相似度。
    """
    num_bits = len(hash1)
    distance = hamming_distance(hash1, hash2)
    similarity = 1 - (distance / num_bits)
    return similarity


if __name__ == '__main__':
    # str1 = 'This is a test text for similarity calculation using Karp-Rabin algorithm'
    # str2 = 'This is a test text for similarity calculation using Karp-Rabin algorithm and a little long'
    str1 = '北京增值税电子普通发票.pdf'
    str2 = '福建增值税电子普通发票.pdf'
    str3 = '福建工程学院计算机学院培养方案.pdf'

    # 生成示例文本的Karp-Rabin文件指纹
    fingerprint1 = generate_karprabin_fingerprint(str1)
    fingerprint2 = generate_karprabin_fingerprint(str2)
    fingerprint3 = generate_karprabin_fingerprint(str3)

    print("Karp-Rabin文件指纹示例:")
    print("str1:", fingerprint1)
    print("str2:", fingerprint2)
    print("str3:", fingerprint3)

    # 计算相似度
    # similarity = calculate_similarity(fingerprint1, fingerprint2)
    # print(f"相似度: {similarity}")
    similarity_12 = calculate_similarity(fingerprint1, fingerprint2)
    similarity_13 = calculate_similarity(fingerprint1, fingerprint3)
    similarity_23 = calculate_similarity(fingerprint2, fingerprint3)

    print(f"相似度1和2: {similarity_12}")
    print(f"相似度1和3: {similarity_13}")
    print(f"相似度2和3: {similarity_23}")
```

1. **指纹生成**

   `generate_karprabin_hash`函数用于生成文本的指纹。它接受文本字符串作为输入，并使用Karp-Rabin算法计算滑动窗口的哈希值，然后将所有窗口的哈希值连接起来，作为整个字符串的指纹。

2. **指纹相似度计算**

   1. hamming_distance函数用于计算两个字符串之间的汉明距离。它接受两个字符串的哈希值作为输入，并通过逐位比较两个哈希值的不同位数，计算汉明距离。
   2. calculate_similarity函数用于计算两个字符串之间的相似度。它接受两个字符串的哈希值作为输入，并使用汉明距离计算相似度。相似度计算的方法是通过将汉明距离除以哈希值的总位数，得到相似度。

3. **效果：常见的处理方法都具有局限性**
   1. 简单拼接每一个小窗口的hash值，可能会导致最终文档指纹长度不同，无法计算汉明距离
   2. 当两个字符串的相似部分位于不同位置时，Karp-Rabin算法无法判断出这种相似性，因为他们分别位于指纹的不同部分。
   
   ```
   Karp-Rabin文件指纹示例:
   str1: 2778544045329935378749
   str2: 24100544045329935378749
   str3: 43939476678617353876343989
   相似度1和2: 0.13636363636363635
   相似度1和3: 0.18181818181818177
   相似度2和3: 0.08695652173913049
   ```

**优化思路：**

1. 把这种“内容顺序相关”的指纹生成模式转变为“集合式的”，要让不同文档中相同部分位于指纹的同一片区。、
2. 需要想方法统一最终生成的指纹长度
3. 这样想起来其实没啥考虑这种方法的必要了，相比于simhash等方法实在是有点原始。
4. 其实感觉winnowing就是基于karp-rabin思想形成的指纹生成方法



### 4、Winnowing

#### 原理

Winnowing算法是一种用于文本数据的局部散列算法，主要用于文本去重和查找近似重复的文本片段。该算法基于散列函数，可以快速地生成文本的指纹，从而方便地进行文本相似性的计算。Winnowing可以有效地识别重复的文本段落或者检测抄袭文本。

**算法原理：**

基本思想是将文本分成固定大小的滑动窗口，在每个窗口内使用散列函数计算散列值，然后在所有窗口中选择散列值最小的一个作为该位置的指纹。通过这种方式，Winnowing算法可以过滤掉文本中的噪声和不重要的信息，保留重要的特征，从而实现文本去重和相似性计算。

**k-grams+Winnowing算法步骤：**

1. **生成k-grams**：将原始文本切分成连续的k个字符的子串，这些子串被称为k-grams。k-grams是文本的局部特征表示，能够捕捉文本的局部信息。
2. **计算k-grams的哈希值**：对于生成的每个k-gram子串，使用哈希函数将其转换为哈希值。这一步将k-grams映射为哈希值，缩小了指纹的维度。
3. **选取局部最小哈希值**：在生成的哈希值列表中，选择局部最小的哈希值作为该位置的指纹。具体做法是定义一个滑动窗口，在窗口内找到最小的哈希值，并记录下来。随着窗口滑动，不断更新最小值，得到文本的指纹。
4. **连接指纹**：将不同位置的指纹连接起来，形成整个文本的指纹表示。这样，每个文本都会有一串指纹值，代表了文本的局部特征。
5. **存储指纹**：将生成的文本指纹存储起来，用于后续的文本相似度计算和比较。

**应用场景：**k-grams+Winnowing算法主要用于文本相似度计算，特别是对于较长文本的相似度比较。通过局部特征的表示，可以捕捉文本的相似部分，而Winnowing算法的局部最小哈希选择策略能够进一步减少指纹的维度，提高计算效率。这种算法适用于大规模文本相似度比较和查重等应用场景。

**参考教程：**

[(107条消息) 【文本相似性计算】winnowing算法_夜谷子的博客-CSDN博客](https://blog.csdn.net/weixin_43098787/article/details/82837867)

[(107条消息) winnowing 算法 -- 提取文档指纹特征**winnowing算法**ouprince的博客-CSDN博客](https://blog.csdn.net/qq_32023541/article/details/82382808)

[(107条消息) 基于K-gram的winnowing特征提取剽窃查重检测技术（概念篇）**kgramhash**君的名字的博客-CSDN博客](https://blog.csdn.net/chichoxian/article/details/53115067?spm=1001.2101.3001.6650.2&utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-2-53115067-blog-82382808.235^v38^pc_relevant_anti_t3_base&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-2-53115067-blog-82382808.235^v38^pc_relevant_anti_t3_base&utm_relevant_index=3)

[基于 Hash 与 Winnowing 方法的文档查重 | nameoverflow (hcyue.me)](https://hcyue.me/2017/05/11/plagiarism-detection/)

**PS1：hash选择和相似度算法选择**

> 1. hash理论上用啥都差别不大？？？？？？待探索
> 2. 由于文档长度不同，其实更适合以集合式的方式来计算，比如选择jaccard相似度。

---
#### 代码

```python
from simhash import Simhash
import hashlib


def generate_kgrams(text, k):
    """
    生成k-grams列表。
    :param text: 要生成k-grams的文本。
    :param k: k-grams的长度。
    :return: k-grams列表。
    """
    kgrams = []
    for i in range(len(text) - k + 1):
        kgram = text[i:i + k]
        kgrams.append(kgram)
    return kgrams


def calculate_hashes(kgrams):
    """
    计算k-grams的哈希值列表。
    :param kgrams: k-grams列表。
    :return: 哈希值列表(10进制)。
    """
    hashes = []
    for kgram in kgrams:
        hash_value = hashlib.sha1(kgram.encode('utf-8'))
        hash_value = hash_value.hexdigest()[-4:]
        hash_value = int(hash_value, 16)  # using last 16 bits of sha-1 digest
        # 也可以换其他hash
        hashes.append(hash_value)
    return hashes


def winnowing(hashes, window_size):
    """
    使用Winnowing算法从哈希列表中生成文本的指纹。
    :param hashes: 哈希值列表。
    :param window_size: 滑动窗口大小。
    :return: 文本的指纹集合(10进制)。
    """
    min_hashes = []
    # 找到初始窗口中的最小哈希值(若有重复选最右边)
    min_pos, min_hash = 0, hashes[0]
    for i, x in enumerate(hashes[0:window_size]):
        if x <= min_hash:
            min_pos, min_hash = i, x
    min_hashes.append(min_hash)

    # 滑动窗口，选择局部最小哈希值
    for i in range(1, len(hashes) - window_size + 1):
        if min_pos < i:
            min_pos, min_hash = i, hashes[i]
            for pos, x in enumerate(hashes[i:window_size + i]):
                if x <= min_hash:
                    min_pos, min_hash = pos + i, x
            min_hashes.append(min_hash)
        elif hashes[i + window_size - 1] <= min_hash:
            min_pos = i + window_size - 1
            min_hash = hashes[i + window_size - 1]
            min_hashes.append(min_hash)

    return min_hashes


def kgrams_winnowing(text, k, window_size):
    """
    使用k-grams+Winnowing算法生成文本的指纹。
    :param text: 要生成指纹的文本。
    :param k: k-grams的长度。
    :param window_size: 滑动窗口大小。
    :return: 文本的指纹(一个list结构，包含选出的多个hash值，10进制int表示)。
    """
    kgrams = generate_kgrams(text, k)
    hashes = calculate_hashes(kgrams)
    fingerprints = winnowing(hashes, window_size)
    return fingerprints


# def calculate_hamming_similarity(fingerprints1, fingerprints2):
#     """
#     计算两个文本指纹之间的汉明距离相似度（基于思想略做修改——原始汉明距离是算01串的差别，但是winnowing算法得到的值其实每一个小部分的十进制哈希和
#     其它算法得到的一个位的01值维度差不多，所以直接计算每个十进制相同与否就好）。
#     （其实感觉winnowing得到的hash好像不太适合用汉明距离算）
#     :param fingerprints1: 第一个文本的指纹（16进制）。
#     :param fingerprints2: 第二个文本的指纹（16进制）。
#     :return: 相似度。
#     """
#     # 填充两个指纹为一样长
#     if len(fingerprints1) > len(fingerprints2):
#         fingerprints2.extend([0] * (len(fingerprints1) - len(fingerprints2)))
#     elif len(fingerprints1) < len(fingerprints2):
#         fingerprints1.extend([0] * (len(fingerprints2) - len(fingerprints1)))
#     # 计算汉明距离
#     distance = sum(bit1 != bit2 for bit1, bit2 in zip(fingerprints1, fingerprints2))
#     similarity = 1 - (distance / len(fingerprints2))
#     return similarity


def calculate_jaccard_similarity(set1, set2):
    # 计算Jaccard相似度
    intersection = len(set1.intersection(set2))
    union = len(set1.union(set2))
    similarity = intersection / union
    return similarity


if __name__ == '__main__':
    # str1 = 'This is a test text for similarity calculation using k-grams+Winnowing algorithm'
    # str2 = 'This is a  calculation using k-grams+Winnowing algorithm and a little long'
    str1 = '北京增值税电子普通发票.pdf'
    str2 = '福建增值税电子普通发票.pdf'
    str3 = '福建工程学院计算机学院培养方案.pdf'

    k = 2  # k值，根据实际情况设定
    window_size = 4  # 滑动窗口大小，根据实际情况设定

    fingerprint1 = kgrams_winnowing(str1, k, window_size)
    fingerprint2 = kgrams_winnowing(str2, k, window_size)
    fingerprint3 = kgrams_winnowing(str3, k, window_size)

    print("Winnowing文件指纹示例:")
    print("str1:", fingerprint1)
    print("str2:", fingerprint2)
    print("str3:", fingerprint3)

    # 计算相似度
    # similarity_12 = calculate_hamming_similarity(fingerprint1, fingerprint2)
    # similarity_13 = calculate_hamming_similarity(fingerprint1, fingerprint3)
    # similarity_23 = calculate_hamming_similarity(fingerprint2, fingerprint3)
    #
    # print(f"汉明相似度1和2: {similarity_12}")
    # print(f"汉明相似度1和3: {similarity_13}")
    # print(f"汉明相似度2和3: {similarity_23}")

    similarity2_12 = calculate_jaccard_similarity(set(fingerprint1), fingerprint2)
    similarity2_13 = calculate_jaccard_similarity(set(fingerprint1), fingerprint3)
    similarity2_23 = calculate_jaccard_similarity(set(fingerprint2), fingerprint3)

    print(f"jaccard相似度1和2: {similarity2_12}")
    print(f"jaccard相似度1和3: {similarity2_13}")
    print(f"jaccard相似度2和3: {similarity2_23}")

```

1. **指纹生成**
   1. kgrams_winnowing(text, k, window_size)函数是整个算法的入口函数。它依次调用generate_kgrams、calculate_hashes和winnowing函数，生成文本的指纹。

   2. generate_kgrams(text, k)函数用于生成文本的k-grams列表。K-grams是文本中长度为k的连续子串。通过滑动窗口，从文本中提取出所有的k-grams，并存储在一个列表中。

   3. calculate_hashes(kgrams)函数用于计算k-grams的哈希值列表。这里使用了sha1算法的末四位来计算k-grams的哈希值，将其值转换成十进制数，并将哈希值存储在一个列表中。

   4. winnowing(hashes, window_size)函数用于使用Winnowing算法从哈希值列表中生成文本的指纹。Winnowing算法通过滑动窗口，在哈希值列表中选择局部最小的哈希值，然后将这些最小哈希值作为文本的指纹。

2. **指纹相似度计算**
   
1. `calculate_jaccard_similarity(set1, set2)`函数用于计算两个字符串之间的jaccard相似度。jaccard相似度是计算两个集合的交集与并集之比。
   
3. 效果：还可以

   PS：需要根据后续测试来选择合适的k和window_size以及哈希函数

   ```
   Winnowing文件指纹示例:
   str1: [13896, 11496, 1534]
   str2: [13896, 11496, 1534]
   str3: [16408, 18059, 22285, 28193, 1258, 1534]
   jaccard相似度1和2: 1.0
   jaccard相似度1和3: 0.1111111111111111
   jaccard相似度2和3: 0.1111111111111111
   ```



---

## 三、文档指纹相似度比较方法

### 1、汉明距离

汉明距离（Hamming distance）是一种衡量两个等长字符串之间差异的度量方法。它用于计算两个字符串在相同位置上不同字符的个数。换句话说，汉明距离衡量了将一个字符串转换为另一个字符串所需的最小替换次数。

**汉明距离计算方法：**

1. 首先，将两个字符串对齐，使它们的长度相同。如果两个字符串长度不同，需要在较短的字符串末尾补充空字符，直到两个字符串的长度相等。
2. 然后，逐个比较两个字符串在相同位置上的字符。如果两个字符不相同，则汉明距离加1；如果两个字符相同，则汉明距离不变。
3. 最后，将所有不相同字符的个数相加，得到最终的汉明距离。
4. 若计算相似度，则通过计算汉明距离与输入二进制串长度的比值来得到相似度。

**PS：如果是不等长字符串**：常见的做法是先将它们转换成等长的特征向量，然后再计算特征向量之间的相似度。常见的方法包括使用**N-gram特征或TF-IDF特征**等。(但感觉有点大材小用)

> **N-gram特征：**N-gram是一种将文本切分为连续的N个字符或单词的方法。对于每个字符串，我们可以将其切分为N-gram，使用词袋模型（Bag of Words）或其他方法，其中向量的每个维度对应一个N-gram，值表示该N-gram在文本中的出现频率或存在与否，形成一个特征向量。
>
> **TF-IDF特征:** 对于每个文本，计算其中每个词的TF（词频，出现的次数）和IDF（逆文档频率，反映该词在整个语料库中的重要性）。 将文本的TF-IDF值构成一个特征向量，其中每个维度对应一个词，值表示该词的TF-IDF值。

**代码示例（针对二进制）**

```python
def hamming_distance(fingerprint1, fingerprint2, cal_simi=True):
    """
    计算两个指纹的汉明距离。
    :param fingerprint1: 第一个指纹
    :param fingerprint2: 第二个指纹（需保证两个指纹等长）
    :param cal_simi: 是否计算相似度
    :return: 汉明距离, [相似度]
    """
    if isinstance(fingerprint1, Simhash):
        hamming_dist = fingerprint1.distance(fingerprint2)
        if cal_simi:
            if fingerprint1.f != fingerprint2.f:
                raise ValueError("fingerprint1 and fingerprint2 in type of Simhash must have same dimension!")
            simi = 1 - (hamming_dist / fingerprint1.f)  # fingerprint1.f为simhash指纹维度
            return hamming_dist, simi
        return hamming_dist
    elif isinstance(fingerprint1, int):
        bin1 = bin(fingerprint1)[2:]
        bin2 = bin(fingerprint2)[2:]
        if len(bin1) != len(bin2):
            raise ValueError("input fingerprints in type of int must have same dimension!")
        xor_result = fingerprint1 ^ fingerprint2
        hamming_dist = bin(xor_result).count('1')
        if cal_simi:
            simi = 1 - (hamming_dist / len(bin1))
            return hamming_dist, simi
        return hamming_dist
    elif isinstance(fingerprint1, str):
        if len(fingerprint1) != len(fingerprint2):
            raise ValueError("input fingerprints in type of str must have same dimension!")
        hamming_dist = sum(bit1 != bit2 for bit1, bit2 in zip(list(fingerprint1), list(fingerprint2)))
        if cal_simi:
            dim = len(fingerprint1)
            simi = 1 - (hamming_dist / dim)
            return hamming_dist, simi
        return hamming_dist
    else:
        raise TypeError("input fingerprints must be in type of Simhash, int or str")
```

 

### 2、Jaccard相似度

Jaccard相似度是一种用于计算两个集合之间相似性的指标，它衡量两个集合的交集元素与并集元素之间的比例。Jaccard相似度的取值范围在0到1之间，其中0表示两个集合没有共同的元素，1表示两个集合完全相同。

**Jaccard相似度的计算方法：**

1. 首先，计算两个集合的交集，即两个集合中共有的元素。
2. 然后，计算两个集合的并集，即两个集合中所有的元素，包括重复的元素。

3. 最后，用交集的大小除以并集的大小，得到Jaccard相似度。

数学表达式为：J(A, B) = |A ∩ B| / |A ∪ B|

其中，J(A, B)表示集合A和集合B的Jaccard相似度，|A ∩ B|表示集合A和集合B的交集大小，|A ∪ B|表示集合A和集合B的并集大小。

Jaccard相似度在数据处理和信息检索中广泛应用，特别适用于处理文本数据、集合数据、网络图等。在文件指纹相似度计算中，Jaccard相似度也常用于衡量两个文件指纹之间的相似性。

**代码示例：（常用于set集合类型数据计算相似度）**

```python
def jaccard_similarity(data1, data2):
    """
    计算集合的jaccard相似度。
    :param data1: 第一个数据，set/list/MinHash
    :param data2: 第二个数据，set/list/MinHash
    :return: jaccard值，float
    """
    if isinstance(data1, set):
        intersection = len(data1.intersection(data2))
        union = len(data1.union(data2))
        return intersection / union
    elif isinstance(data1, list):
        data1 = set(data1)
        data2 = set(data2)
        intersection = len(data1.intersection(data2))
        union = len(data1.union(data2))
        return intersection / union
    elif isinstance(data1, MinHash):
        return data1.jaccard(data2)  # 使用minhash估计的jaccard值
```



### 3、余弦相似度

余弦相似度（Cosine Similarity）是一种常用的相似度计算方法，它可以用于衡量两个向量之间的相似程度。在文本相似度计算中，可以将文本表示成向量，然后使用余弦相似度来比较两个文本的相似性。

**余弦相似度的计算方法：**

假设有两个向量A和B，它们分别是n维向量（可以是词频向量、TF-IDF向量等），那么余弦相似度可以通过以下公式计算：

其中，A · B表示向量A和向量B的点积（内积），||A||表示向量A的模长，||B||表示向量B的模长。

余弦相似度的取值范围在[-1, 1]之间，取值越接近1表示两个向量越相似，取值越接近-1表示两个向量越不相似，取值为0表示两个向量正交（无相似性）。

**代码示例：**

1. 基于TF-IDF生成文本向量，并计算余弦相似度：

    ```python
    def tfidf_based_cosine_similarity(text1, text2):
        """
        基于TF-IDF计算两个文本之间的余弦相似度。
        :param text1: 第一个文本
        :param text2: 第二个文本
        :return: 余弦相似度
        """
        vectorizer = TfidfVectorizer(use_idf=True, norm='l2')
        tfidf_matrix = vectorizer.fit_transform([text1, text2])
        cosine_sim = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]
        return cosine_sim
    ```

### 4. WMD

```
def wmd_distance(text1, text2):
    """
    计算两个文本之间的wmd距离。
    :param text1: 第一个文本，str
    :param text2: 第二个文本，str
    :return: wmd距离，float
    """
    text1 = remove_stopwords(text1)
    text2 = remove_stopwords(text2)
    model = api.load('word2vec-google-news-300')
    dist = model.wmdistance(text1, text2)
    return dist
```





## 四、文档相似度计算全流程

### N-gram + Minhash+Locality Sensitive Hashing (LSH)

#### 原理

N-gram是一种文本特征表示方法，可以将文本切分为连续的N个字符或词语。通过将字符串内容转换为N-gram特征，并使用LSH将相似的N-gram特征分到同一个桶中，可以生成类似的文本指纹。

**1.** **N-gram：** N-gram是一种文本特征提取方法，它将文本划分为连续的N个字符或词语。N-gram模型可以捕捉文本中的局部特征和上下文信息。常见的N-gram模型包括unigram（单个字符或词语）、bigram（两个连续字符或词语）、trigram（三个连续字符或词语）等。通过提取文本的N-gram特征，我们可以将文本转化为向量表示，便于后续的相似度计算。

**2.** **Locality Sensitive Hashing (LSH)：** LSH是一种近似搜索算法，用于快速查找近似相似的数据项。在文本相似度计算中，LSH可用于快速搜索相似的N-gram向量，以便在大规模文本数据集中找到相似的文本。LSH通过哈希函数将向量映射到桶（bucket）中，相似的向量在同一个桶中的概率较高。通过只计算同一桶内的向量之间的相似度，大大减少了相似度计算的时间复杂度。

**N-gram + LSH的流程**如下：

1. 对文本进行N-gram特征提取，将文本转化为N-gram向量表示。
2.  使用LSH算法将N-gram向量映射到不同的桶中。
3. 在每个桶内计算向量之间的相似度，找到近似相似的文本。

**应用场景：**处理大规模文本数据的相似度搜索和近似匹配

**参考教程：**[可搜索加密：基础知识-腾讯云开发者社区-腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/2205117?areaSource=102001.7&traceId=eEiYFBEodUbaVIwPmqCP1)

---

#### 代码

```

```



#### ***\*（1）指纹生成\****

generate_ngram_lsh_fingerprint

\1. 对于每个文本，首先进行N-gram处理，获取输入文本的N-gram序列。N-gram是指将文本划分为连续的N个字符或词组的序列。N可以根据需要进行调整。

\2. 对于每个N-gram序列，将其转换为字符串形式，并计算其哈希值（哈希函数可以进行调整）。

\3. 将计算得到的哈希值添加到 MinHash 对象中。

\4. 返回 MinHash 对象的摘要值：

PS：可以调整N-gram的大小（n），MinHash的排列数（num_perm）和LSH的阈值（threshold）来获得更好的指纹效果

打印二进制摘要、哈希摘要

#### ***\*（2）指纹相似度计算\****

hamming_distance函数用于计算两个指纹之间的汉明距离。然后，calculate_similarity函数使用***\*汉明距离\****计算两个指纹的相似度。相似度的计算公式是 1 - (汉明距离 / 指纹长度)。

PS：可以考虑使用Jaccard相似度计算

效果：效果不错

1  处理后的指纹（哈希值）:

2  str1: a33d4c4e78166ea389699c2db12b7973

3  str2: 882ed74f91d19ee27582bd43b244751a

4  str3: 20a43e7e1509294247f91bc87891fa83

5  1和2两个文本的相似度为: 0.78125

6  1和3两个文本的相似度为: 0.15625

7  2和3两个文本的相似度为: 0.2734375



## 五、相似文档搜索技术

### LSH—局部敏感哈希

#### 原理

**Locality Sensitive Hashing**

* LSH是一种用于在高维空间中快速搜索相似项的**近似搜索技术**（相比于某种hash方法，更强调一种搜索技术，在已经得到文档指纹后，如何用比一次比较的方式更快地找出最相似目标！）

**算法思想：**

1. 将签名矩阵分为 b 个频带（band），每个带有 r 行。

   eg. 假设三个文档的文档签名分别是1232,1232,3123，

   ```
   Bands   Doc1    Doc2   Doc3  
   ------------------------------
   band1     1       1      3     
             2       2      1     
   ------------------------------
   band2     3       3      2     
             2       2      3
   ```

2. 对于每个频带，将其每列的对应部分散列到具有 k 个桶的散列表中

   ```
   Bucket 1 
   Doc1,band1 {1,2} 
   Doc2,band1 {1,2} 
   ---- o0o ---- o0o ---- o0o ---- o0o ---- 
   Bucket 2 
   Doc1,band2 {3,2} 
   Doc2,band2 {3,2} 
   ---- o0o ---- o0o ---- o0o ---- o0o ---- 
   Bucket 3 
   Doc3,band1 {3,1} 
   ---- o0o ---- o0o ---- o0o ---- o0o ---- 
   Bucket 4 
   Doc3,band2 {2,3}
   ```

3. 如果两个文档位于相同的存储桶中（1 个或更多），则它们是相似性的候选者

4. 调整 b 和 r 值以捕获大多数相似项，但很少有非相似项

**K-gram/N-gram + LSH算法步骤：****

1. 选择合适的K-gram或者N-gram大小：根据应用的需要，选择合适的K-gram或者N-gram大小，将文本划分为连续的K个字符或者N个连续的词组。

2. 生成文本的指纹：对于每个文本，使用K-gram或者N-gram来生成文本的指纹。可以使用哈希函数将K-gram或者N-gram序列映射为一个哈希值，得到文本的指纹。

3. 建立LSH索引：使用LSH算法来建立索引，将所有生成的文本指纹划分到不同的桶中。在datasketch库中，可以使用MinHashLSH/SimhashLSH类来实现LSH索引。

4. 添加指纹到LSH索引：将生成的文本指纹添加到LSH索引中的对应桶中。

5. 查询相似指纹：对于要查询相似度的文本，先生成其指纹，然后使用LSH索引进行查询，找到与查询指纹相似的其他指纹。可以使用**`datasketch包中的MinHashLSH/simhash包中的SimhashIndex`**类的query方法来实现查询。

**应用场景：**处理大规模文本数据的相似度搜索和近似匹配

**参考教程：**[可搜索加密：基础知识-腾讯云开发者社区-腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/2205117?areaSource=102001.7&traceId=eEiYFBEodUbaVIwPmqCP1)

---

#### 代码

1. simhash

   ```python
   from simhash import Simhash, SimhashIndex
   
   # ......
   
   def simhashLSH_search(objs, simhash, k=2):
       '''
       :param objs: (obj_name, simhash)的列表
       :param simhash: 待查询的simhash
       :param k: k为分片数，越大越精确，但是越慢，同时k也代表了对于相似度的容忍度，k越大，
       :return:
       '''
       index = SimhashIndex(objs, k=k)
       print(index.bucket_size())
       return index.get_near_dups(simhash)
   
   
   if __name__ == '__main__':
       str1 = '北京增值税电子普通发票.pdf'
       str2 = '福建增值税电子普通发票.pdf'
       str3 = '福建工程学院计算机学院培养方案.pdf'
   
    # ......
   
       # 使用SimhashIndex查询相似项（这一步可以在大规模数据中进行快速相似项查询）(实际上是一种LSH方法的实现)
       objs = [("str1", fingerprint1), ("str2", fingerprint2), ("str3", fingerprint3)]
       fingerprint4 = generate_simhash_fingerprint("北京电子普通发票.pdf")
       similar_doc = simhashLSH_search(objs, fingerprint4, k=16)
       print(similar_doc)
   ```
   
   
   
2. minhash

   ```python
   from datasketch import MinHash, MinHashLSH
   # ......
   
   # 一个用于在大规模数据中进行快速相似项查询的方法
   def minhashLSH_search(minhash_sets, query_set):
       lsh = MinHashLSH(threshold=0.5, num_perm=128)  # threshhold是判定是否相似的jaccard阈值
       for name, set in minhash_sets.items():
           lsh.insert(name, set)
       return lsh.query(query_set)
   
   if __name__ == '__main__':
       set1 = {'apple', 'banana', 'orange', 'grape'}
       set2 = {'apple', 'watermelon', 'banana', 'kiwi'}
       str3 = '北京增值税电子普通发票.pdf'
       str4 = '福建增值税电子普通发票.pdf'
       str5 = '福建工程学院计算机学院培养方案.pdf'
       # ......
   
       # 使用MinHashLSH查询相似项（这一步可以在大规模数据中进行快速相似项查询）
       sets = {"set1": minhash1, "set2": minhash2, "set3": minhash3, "set5": minhash5}
       result = minhashLSH_search(sets, minhash4)
       print("MinHashLSH查询相似项：", result)
   
   ```

   

